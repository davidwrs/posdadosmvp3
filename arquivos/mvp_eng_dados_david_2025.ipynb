{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef0f6e97-eeae-445a-86bc-760540e24483",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PUC - Rio | Ciência de Dados e Analytics\n",
    "## MVP Engenharia de dados\n",
    "### David William Rosa de Souza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94cd6a5d-dd66-4c50-bebd-7d7dec0b5639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Objetivo / Contexto\n",
    "O objetivo deste projeto é desenvolver um pipeline de dados completo utilizando a plataforma Databricks, contemplando ingestão, transformação, modelagem, carga e análise. O dataset escolhido é proveniente do Banco Central e permite a construção de um Data Warehouse em modelo dimensional (esquema estrela), adequado para consultas analíticas sobre movimentações financeiras da população brasileira.\n",
    "\n",
    "---------\n",
    "\n",
    "## Problema\n",
    "Com o crescimento do Pix em todo território nacional ainda temos poucos estudos e análises mostrando o crescimento/adesão, regiões que mais utilizam o serviço e distribuição de valor médio. Por isso, com esse trabalho irei aprofundar um pouco mais os dados para tirar insights que podem ajudar agentes públicos a entender melhor a distribuição do uso desse serviço que revolucionou o mercado financeiro no Brasil.\n",
    "\n",
    "---------\n",
    "\n",
    "## Fonte dos Dados\n",
    "Os dados foram obtidos no canal oficial do Banco Central através do link:\n",
    "https://dadosabertos.bcb.gov.br/dataset/pix\n",
    "\n",
    "Opção → Estatísticas de transações PixJSON\n",
    "\n",
    "Opção → Explorar\n",
    "\n",
    "Opção → Ir para recurso\n",
    "\n",
    "No item “data-base” foi informado “2025” \n",
    "\n",
    "No item “máximo” foi informado “500000”\n",
    "\n",
    "No item “saída” foi selecionado CSV\n",
    "\n",
    "No item “campos” foram selecionadas todas opções\n",
    "\n",
    "Depois cliquei em baixar CSV\n",
    "\n",
    "o arquivo foi atualizado no meu github no link\n",
    "\n",
    "github.com/davidwrs/posdadosmvp3/blob/main/202512-estatisticas-transacoes-pix.csv \n",
    "\n",
    "e será a partir dele que serão feitas as análises deste trabalho.\n",
    "\n",
    "---------\n",
    "\n",
    "## Perguntas a serem respondidas\n",
    "As principais perguntas de negócio definidas para este MVP são:\n",
    "\n",
    "1 - Em qual ano/mês as transferências PIX entre pessoas físicas (PF → PF) atingiram superior a R$ 100 bilhões?\n",
    "\n",
    "2 - Em qual ano/mês as transferências PIX de pessoas físicas para pessoas jurídicas (PF → PJ) atingiram um superior a R$ 100 bilhões?\n",
    "\n",
    "3 - Qual é a distribuição do valor médio das transferências PIX por região geográfica no Brasil?\n",
    "\n",
    "4 - Quais regiões geográficas concentram os maiores volumes de envio de transferências PIX?\n",
    "\n",
    "5 - Quais regiões geográficas concentram os maiores volumes de recebimento de transferências PIX?\n",
    "\n",
    "---------\n",
    "\n",
    "## Metodologia\n",
    "\n",
    "A metodologia adotada neste trabalho baseia-se na arquitetura Medallion, estruturada nas camadas **Bronze**, **Silver** e **Gold**, amplamente utilizada em pipelines de dados analíticos.\n",
    "\n",
    "A camada **Bronze** foi utilizada para a ingestão e armazenamento dos dados brutos, preservando integralmente a estrutura original fornecida pela fonte de dados. Essa camada representa a cópia fiel dos dados de origem e serve como base para as etapas subsequentes do pipeline.\n",
    "\n",
    "Na camada **Silver**, os dados passaram por processos de tratamento e padronização, tornando-os adequados para análise e modelagem. Essa etapa foi responsável por garantir a consistência dos tipos de dados, a organização temporal e a padronização dos atributos categóricos.\n",
    "\n",
    "Por fim, a camada **Gold** concentrou a modelagem analítica dos dados, por meio da construção de um modelo dimensional em esquema estrela, composto por uma tabela fato central e tabelas de dimensão. Essa camada foi projetada para facilitar consultas analíticas e responder às perguntas de negócio definidas no escopo do trabalho.\n",
    "\n",
    "\n",
    "## Ferramentas\n",
    "\n",
    "- Databricks: Plataforma unificada para desenvolvimento, execução e gerenciamento do pipeline de dados.\n",
    "\n",
    "- Apache Spark (SQL e PySpark): Engine de processamento distribuído utilizado para manipulação eficiente de grandes volumes de dados e execução das transformações e análises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e82efde7-f691-48f2-9532-f0bc0a77105d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modelagem dos Dados\n",
    "\n",
    "A modelagem dos dados na camada Gold foi realizada a partir do modelo dimensional em esquema estrela, amplamente utilizado em ambientes analíticos e de Business Intelligence. Esse modelo foi escolhido por sua simplicidade, eficiência em consultas analíticas e facilidade de interpretação dos dados, especialmente em cenários que envolvem grandes volumes de informações, como é o caso das transações PIX.\n",
    "\n",
    "---\n",
    "\n",
    "### Diagrama simplificado\n",
    "\n",
    "![diagrama-simplificado.png](https://raw.githubusercontent.com/davidwrs/posdadosmvp3/602ff54aa63c53a38cc6b1426cea976cabcdde5b/diagrama-simplificado.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Tabela Fato\n",
    "\n",
    "A tabela fato foi criada com o objetivo de centralizar as métricas quantitativas relacionadas às transações financeiras, representando o núcleo analítico do modelo. Nela são armazenados os principais indicadores do negócio, como o valor total das transações em reais e a quantidade de transações realizadas, além das referências às dimensões que contextualizam cada ocorrência.\n",
    "\n",
    "No contexto deste trabalho, a tabela fato fato_transacoes_pix permite analisar o comportamento das transações ao longo do tempo, por região, tipo de pessoa (pagador e recebedor) e faixa etária, viabilizando a realização de agregações, comparações e análises temporais de forma eficiente. Essa centralização das métricas facilita a execução de consultas analíticas complexas com melhor desempenho e menor complexidade de SQL.\n",
    "\n",
    "----\n",
    "\n",
    "Tabela e colunas:\n",
    "\n",
    "\n",
    "_fato_transacoes_pix_\n",
    "\n",
    "\n",
    "- ano\n",
    "- mes\n",
    "- ano_mes\n",
    "- pag_regiao\n",
    "- rec_regiao\n",
    "- pag_tipo_pessoa\n",
    "- rec_tipo_pessoa\n",
    "- pag_faixa_etaria\n",
    "- rec_faixa_etaria\n",
    "- valor_reais\n",
    "- quantidade_total\n",
    "\n",
    "-----\n",
    "\n",
    "## Tabelas de dimensões\n",
    "\n",
    "As tabelas de dimensão foram criadas para armazenar os atributos descritivos que fornecem contexto às métricas da tabela fato. Cada dimensão representa um eixo de análise específico, permitindo a segmentação e o detalhamento dos dados de acordo com diferentes perspectivas.\n",
    "\n",
    "A dimensão Tempo (dim_tempo) possibilita análises temporais, como comparações mensais e anuais, sendo fundamental para identificar tendências e padrões ao longo do período analisado.\n",
    "\n",
    "Tabela e colunas:\n",
    "\n",
    "_dim_tempo_\n",
    "\n",
    "- ano\n",
    "- mes\n",
    "- ano_mes\n",
    "\n",
    "\n",
    "A dimensão Região (dim_regiao) permite avaliar a distribuição geográfica das transações, identificando quais regiões concentram maior volume de envio ou recebimento de valores.\n",
    "\n",
    "Tabela e colunas:\n",
    "\n",
    "_dim_regiao_\n",
    "\n",
    "- regiao\n",
    "\n",
    "\n",
    "A dimensão Tipo de Pessoa (dim_tipo_pessoa) viabiliza a distinção entre transações realizadas por pessoas físicas e jurídicas, elemento essencial para responder às perguntas de negócio definidas neste trabalho.\n",
    "\n",
    "\n",
    "Tabela e colunas:\n",
    "\n",
    "\n",
    "_dim_tipo_pessoa_\n",
    "\n",
    "\n",
    "tipo_pessoa\n",
    "\n",
    "A dimensão Faixa Etária (dim_faixa_etaria) fornece uma visão demográfica das transações, permitindo analisar o comportamento dos usuários conforme diferentes grupos etários.\n",
    "\n",
    "\n",
    "Tabela e colunas:\n",
    "\n",
    "\n",
    "_dim_faixa_etaria_\n",
    "\n",
    "\n",
    "- faixa etaria\n",
    "\n",
    "\n",
    "A separação entre fato e dimensões contribui para a redução de redundância, maior organização dos dados e melhor legibilidade das consultas, além de facilitar a manutenção e a evolução do modelo analítico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1bd9c28-fb9b-46bf-a84e-2602779ab617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Carga de dados\n",
    "\n",
    "A etapa de carga dos dados foi realizada por meio de notebooks na plataforma Databricks, utilizando PySpark, o que permitiu a execução de processos distribuídos e escaláveis para ingestão, transformação e organização dos dados. Essa etapa foi estruturada seguindo a arquitetura estrela, composta pelas camadas Bronze, Silver e Gold, garantindo separação de responsabilidades, rastreabilidade dos dados e facilidade de manutenção do pipeline.\n",
    "\n",
    "## Extração e Carga da Camada Bronze\n",
    "\n",
    "Na camada Bronze foi realizada a extração dos dados brutos do conjunto de transações PIX disponibilizado pelo Banco Central do Brasil. Os dados foram carregados em seu formato original, sem alterações semânticas, preservando integralmente as informações fornecidas pela fonte oficial.\n",
    "\n",
    "Essa camada tem como principal objetivo atuar como um repositório histórico dos dados brutos, assegurando a possibilidade de reprocessamento futuro e auditoria das informações. Durante essa etapa, os dados foram armazenados no ambiente Databricks utilizando mecanismos nativos de leitura e persistência, garantindo confiabilidade e integridade no processo de ingestão.\n",
    "\n",
    "A utilização do PySpark nesta fase permitiu lidar de forma eficiente com o volume de dados, além de preparar o ambiente para as transformações subsequentes.\n",
    "\n",
    "## Camada Silver\n",
    "\n",
    "A camada Silver concentrou os processos de tratamento, padronização e enriquecimento dos dados. Nessa etapa, os dados provenientes da Bronze foram transformados para corrigir tipos, padronizar valores categóricos e tornar os atributos adequados para análise.\n",
    "\n",
    "Entre as principais transformações realizadas destacam-se:\n",
    "\n",
    "- conversão de campos originalmente representados como texto para tipos numéricos apropriados;\n",
    "\n",
    "- categorização e padronização das faixas etárias do pagador e do recebedor;\n",
    "\n",
    "- organização de atributos temporais (ano, mês e ano/mês);\n",
    "\n",
    "- validação e padronização de atributos relacionados à região e ao tipo de pessoa.\n",
    "\n",
    "O uso de PySpark possibilitou a aplicação dessas transformações de forma eficiente e reprodutível, garantindo que os dados tratados na Silver estivessem prontos para consumo analítico, sem comprometer a rastreabilidade em relação à camada Bronze.\n",
    "\n",
    "## Camada Gold\n",
    "\n",
    "Na camada Gold foi realizada a modelagem analítica dos dados, com foco na criação de estruturas otimizadas para consulta e análise. A partir dos dados tratados na Silver, foram construídas as tabelas do modelo dimensional em esquema estrela, incluindo a tabela fato e as tabelas de dimensão.\n",
    "\n",
    "Essa etapa teve como objetivo disponibilizar uma base analítica organizada, capaz de responder diretamente às perguntas de negócio definidas no MVP do projeto. As métricas e atributos foram organizados de modo a facilitar agregações, comparações temporais e segmentações por região, tipo de pessoa e faixa etária.\n",
    "\n",
    "A carga da camada Gold consolidou o pipeline de dados, transformando informações brutas em um modelo analítico confiável, escalável e de fácil interpretação, pronto para consultas SQL, visualizações e geração de insights.\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daeaefb9-ded3-495c-8065-25cd88120b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Bronze\n",
    "\n",
    "Abaixo começo pelo importação do notebook 01_bronze_exploracao_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c4d95f4-7b94-434d-b36b-12e8132ee464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "# Camada Bronze\n",
       "\n",
       "Ingestão dos dados brutos baixados do Banco Central e armazenamento em formato Delta Lake (bronze_pix), mantendo a estrutura original. Esta camada serve como nossa fonte primária e é uma cópia fiel dos dados de origem."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Comecei criando uma base chamada bronze dentro do workspace e fiz upload nela do arquivo csv."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run /Workspace/Users/2david.wrs@gmail.com/pos_dados/pipeline_pix/01_bronze_exploracao_pix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a6bdb2c-8c1c-4423-a16f-11bbf5926a59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Silver\n",
    "\n",
    "Depois faço a importação do notebook 02_silver_tramento_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34c1e4e6-008c-485c-8425-2f2c603af376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "A camada Silver contém dados tratados e padronizados, prontos para modelagem.\n",
       "Principais transformações realizadas:\n",
       "\n",
       "- Remover _rescued_data\n",
       "- Padronizar tipos numéricos\n",
       "- Criar colunas de ano e mês\n",
       "- Criar faixa etária (pagador e recebedor)\n",
       "- Padronizar textos (UPPER)\n",
       "- Garantir consistência para análises"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run /Workspace/Users/2david.wrs@gmail.com/pos_dados/pipeline_pix/02_silver_tratamento_pix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf222a6b-ca42-4446-859c-9b4350fff8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Gold\n",
    "\n",
    "Depois faço a importação do notebook 03_gold_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66f30834-0f5e-4d84-8279-7c761b92d9da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "Criar o Schema Bronze (se ainda não existir)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run /Workspace/Users/2david.wrs@gmail.com/pos_dados/pipeline_pix/03_gold_pix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47278248-787a-4137-bc08-93785586e959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Analytics\n",
    "\n",
    "Depois faço a importação do notebook 04_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fabd9540-3124-445e-8efe-bad70a8a6f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/2david.wrs@gmail.com/pos_dados/pipeline_pix/04_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb79ea9-6e29-4877-ae93-b078f2303d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5fd031-55b1-4938-8ed7-58b94db5268d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "------\n",
    "-----\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542b8e77-a7d5-4624-b593-10da9df5e855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Conclusão\n",
    "Na camada gold já podemos ver as respostas de negócio serem respondidas\n",
    "vou passar por cada uma\n",
    "\n",
    "1 - Em qual ano/mês as transferências PIX entre pessoas físicas (PF → PF) atingiram superior a R$ 100 bilhões?\n",
    "\n",
    "R: Em Março de 2021 as transações entre pessoas físicas atigiram um valor superior a R$ 100 bilhões.\n",
    "Como o Pix começou a rodar em novembro de 2020 mostra o sucesso desse serviço e alta taxa de adesão na população brasileira.\n",
    "\n",
    "2 - Em qual ano/mês as transferências PIX de pessoas físicas para pessoas jurídicas (PF → PJ) atingiram um superior a R$ 100 bilhões?\n",
    "\n",
    "R: Somente em novembro de 2022 as transferências de pessoas físicas para pessoas jurídicas atingiram um superior a R$ 100 bilhões.\n",
    "O que mostra que em pagamentos para empresas a população brasileira teve uma adesão mais devagar do que transferências entre pessoas físicas.\n",
    "\n",
    "3 - Qual é a distribuição do valor médio das transferências PIX por região geográfica no Brasil?\n",
    "\n",
    "R: Podemos observar que a região sudeste ainda é a que mais movimenta valores financeiros e sendo a região norte a que menos movimenta.\n",
    "Isso reflete bem a concentração econômica da região sudeste e as desigualdades financeiras do Brasil. \n",
    "\n",
    "4 - Quais regiões geográficas concentram os maiores volumes de envio de transferências PIX?\n",
    "5 - Quais regiões geográficas concentram os maiores volumes de recebimento de transferências PIX?\n",
    "\n",
    "R: E para responder as últimas duas perguntas segue a mesma distribuição de valores médios, sudeste lidera e a região norte é a última.\n",
    "\n",
    "## Autoavaliação\n",
    "\n",
    "O objetivo deste trabalho foi construir um pipeline completo de dados na nuvem, utilizando o Databricks, desde a coleta até a análise, utilizando dados públicos, eu escolhi a base do Pix vinda do Banco Central, pois já tinha utilizado essa base no primeiro MVP o que me ajudou muito por já conhecer a base.\n",
    "\n",
    "De modo geral, os objetivos propostos foram atingidos e fiquei feliz em construir o pipeline. Trabalho como gerente de produtos digitais e a construção e analise de um pipeline já era algo que queria fazer a algum tempo.\n",
    "\n",
    "Passei pelas etapas de coleta, modelagem, carga e analisar os dados. Também respondi as perguntas de negócio definidas no início do trabalho.\n",
    "\n",
    "Já sou formado em analise e desenvolvimento de sistemas, por isso a etapa de entendimento de base, tabelas, colunas, foi muito transparente pra mim. Minha maior dúvida justamente era como coletar dados de um CSV e construir o pipeline e me senti muito satisfeito com o trabalho.\n",
    "\n",
    "A etapa que me gerou mais trabalho foi a silver por causa da limpeza dos dados, foi nela que tive alguns erros e demorei um pouco mais.\n",
    "\n",
    "Tive bastante dificuldade no inicio do enunciado do MVP pois não estava tão claro pra mim o que deveria ser entregue, foi só nas aulas de dúvidas do MVP que o entregavel ficou mais claro.\n",
    "\n",
    "E tive uma dificuldade pra finalizar o trabalho pois na minha conta o databricks passou a informar que já tinha atingido o limite do trial, com isso exportei todos notebooks e subi em outra conta pra finalizar. Deu certo, mas perdi um dia nisso.\n",
    "\n",
    "Atualmente sigo como gerente de produtos digitais em uma instituição financeira e pretendo levar esse conhecimento para meu dia a dia. Fortalezar minha visão analitica em discussões de negócio e quando necessário eu mesmo conseguir fazer o pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52eef21c-4bb7-4dc8-a4d2-938fbabec532",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mvp_eng_dados_david_2025",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}